"""
TrendRadar Web Viewer Server

æä¾›åŸºäº Web çš„æ–°é—»åˆ†ç±»æŸ¥çœ‹å™¨ç•Œé¢
æ”¯æŒå®šæ—¶è‡ªåŠ¨è·å–æœ€æ–°æ•°æ®
"""

import asyncio
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

from fastapi import FastAPI, Request, Query
from fastapi.responses import HTMLResponse, JSONResponse, Response
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
# trendradar/web/server.py -> trendradar/web -> trendradar -> hotnews (é¡¹ç›®æ ¹ç›®å½•)
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from trendradar.web.news_viewer import NewsViewerService
from mcp_server.services.data_service import DataService
from trendradar.crawler import DataFetcher
from trendradar.core import load_config
from trendradar.storage import convert_crawl_results_to_news_data

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(title="TrendRadar News Viewer", version="1.0.0")

# è‡ªå®šä¹‰ JSONResponse ç±»ï¼Œç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º
class UnicodeJSONResponse(Response):
    media_type = "application/json"
    
    def render(self, content) -> bytes:
        return json.dumps(
            content,
            ensure_ascii=False,
            allow_nan=False,
            indent=None,
            separators=(",", ":"),
        ).encode("utf-8")

# é…ç½®æ¨¡æ¿ç›®å½•
templates_dir = Path(__file__).parent / "templates"
templates_dir.mkdir(exist_ok=True)
templates = Jinja2Templates(directory=str(templates_dir))

# å…¨å±€æœåŠ¡å®ä¾‹
_viewer_service: Optional[NewsViewerService] = None
_data_service: Optional[DataService] = None

# å®šæ—¶ä»»åŠ¡çŠ¶æ€
_scheduler_task: Optional[asyncio.Task] = None
_scheduler_running: bool = False
_last_fetch_time: Optional[datetime] = None
_fetch_interval_minutes: int = 30  # é»˜è®¤30åˆ†é’Ÿè·å–ä¸€æ¬¡


def get_services():
    """è·å–æˆ–åˆå§‹åŒ–æœåŠ¡å®ä¾‹"""
    global _viewer_service, _data_service
    
    if _viewer_service is None:
        _data_service = DataService(project_root=str(project_root))
        _viewer_service = NewsViewerService(
            project_root=str(project_root),
            data_service=_data_service
        )
    
    return _viewer_service, _data_service


async def fetch_news_data():
    """æ‰§è¡Œä¸€æ¬¡æ•°æ®è·å–"""
    global _last_fetch_time
    
    try:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ”„ å¼€å§‹è·å–æœ€æ–°æ•°æ®...")
        
        # åŠ è½½é…ç½®
        config = load_config(str(project_root / "config" / "config.yaml"))
        
        # è·å–å¹³å°åˆ—è¡¨ï¼ˆload_config è¿”å›çš„ key æ˜¯å¤§å†™ PLATFORMSï¼‰
        platforms_config = config.get("PLATFORMS", [])
        
        # å¤„ç†åˆ—è¡¨æ ¼å¼ï¼š[{id: "xxx", name: "xxx"}, ...]
        if isinstance(platforms_config, list):
            platforms = {p["id"]: p["name"] for p in platforms_config if isinstance(p, dict) and "id" in p}
        else:
            # å­—å…¸æ ¼å¼ï¼š{id: name, ...}
            platforms = platforms_config
        
        platform_ids = list(platforms.keys())
        
        if not platform_ids:
            print("âš ï¸ æœªé…ç½®ä»»ä½•å¹³å°")
            return {"success": False, "error": "æœªé…ç½®å¹³å°"}
        
        # åˆ›å»ºæ•°æ®è·å–å™¨
        crawler_config = config.get("CRAWLER", {})
        proxy_url = crawler_config.get("proxy_url") if crawler_config.get("use_proxy") else None
        api_url = crawler_config.get("api_url")
        fetcher = DataFetcher(proxy_url=proxy_url, api_url=api_url)
        
        # æ„å»ºå¹³å°IDå’Œåç§°çš„å…ƒç»„åˆ—è¡¨
        platform_tuples = [(pid, platforms[pid]) for pid in platform_ids]
        
        # æ‰¹é‡è·å–æ•°æ®
        crawl_results, id_to_name, failed_ids = fetcher.crawl_websites(platform_tuples)
        
        if not crawl_results:
            print("âš ï¸ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
        
        # è·å–å½“å‰æ—¶é—´
        now = datetime.now()
        crawl_time = now.strftime("%H:%M")
        crawl_date = now.strftime("%Y-%m-%d")
        
        # è½¬æ¢å¹¶ä¿å­˜æ•°æ®
        news_data = convert_crawl_results_to_news_data(
            crawl_results, 
            id_to_name, 
            failed_ids, 
            crawl_time, 
            crawl_date
        )
        
        # è·å–å­˜å‚¨ç®¡ç†å™¨å¹¶ä¿å­˜
        from trendradar.storage import StorageManager
        from trendradar.core import load_config as load_full_config
        
        # ä½¿ç”¨æ­£ç¡®çš„å­˜å‚¨é…ç½®åˆå§‹åŒ–
        storage_config = config.get("STORAGE", {})
        storage = StorageManager(
            backend_type=storage_config.get("backend", "local"),
            data_dir=str(project_root / storage_config.get("local", {}).get("data_dir", "output")),
            enable_txt=storage_config.get("formats", {}).get("txt", False),
            enable_html=storage_config.get("formats", {}).get("html", False),
        )
        storage.save_news_data(news_data)
        
        _last_fetch_time = datetime.now()
        
        # æ¸…é™¤ç¼“å­˜ä»¥åŠ è½½æ–°æ•°æ®
        from mcp_server.services.cache_service import get_cache
        cache = get_cache()
        cache.clear()  # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
        
        # é‡ç½®æœåŠ¡å®ä¾‹
        global _viewer_service, _data_service
        _viewer_service = None
        _data_service = None
        
        total_news = sum(len(items) for items in crawl_results.values())
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… æ•°æ®è·å–å®Œæˆ: {len(crawl_results)} ä¸ªå¹³å°, {total_news} æ¡æ–°é—»")
        
        return {"success": True, "platforms": len(crawl_results), "news_count": total_news}
        
    except Exception as e:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ æ•°æ®è·å–å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}


async def scheduler_loop():
    """å®šæ—¶ä»»åŠ¡å¾ªç¯"""
    global _scheduler_running
    
    while _scheduler_running:
        await fetch_news_data()
        
        # ç­‰å¾…ä¸‹ä¸€æ¬¡æ‰§è¡Œ
        print(f"â° ä¸‹æ¬¡è·å–æ—¶é—´: {_fetch_interval_minutes} åˆ†é’Ÿå")
        await asyncio.sleep(_fetch_interval_minutes * 60)


def start_scheduler(interval_minutes: int = 30):
    """å¯åŠ¨å®šæ—¶ä»»åŠ¡"""
    global _scheduler_task, _scheduler_running, _fetch_interval_minutes
    
    if _scheduler_running:
        print("âš ï¸ å®šæ—¶ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­")
        return
    
    _fetch_interval_minutes = interval_minutes
    _scheduler_running = True
    _scheduler_task = asyncio.create_task(scheduler_loop())
    print(f"âœ… å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨ï¼Œé—´éš”: {interval_minutes} åˆ†é’Ÿ")


def stop_scheduler():
    """åœæ­¢å®šæ—¶ä»»åŠ¡"""
    global _scheduler_task, _scheduler_running
    
    _scheduler_running = False
    if _scheduler_task:
        _scheduler_task.cancel()
        _scheduler_task = None
    print("â¹ï¸ å®šæ—¶ä»»åŠ¡å·²åœæ­¢")


@app.get("/", response_class=HTMLResponse)
async def root(request: Request):
    """é‡å®šå‘åˆ°æŸ¥çœ‹å™¨"""
    return HTMLResponse(
        content='<meta http-equiv="refresh" content="0; url=/viewer">'
    )


@app.get("/viewer", response_class=HTMLResponse)
async def viewer(
    request: Request,
    filter: Optional[str] = Query(None, description="è¿‡æ»¤æ¨¡å¼: strict/moderate/off"),
    platforms: Optional[str] = Query(None, description="å¹³å°åˆ—è¡¨ï¼Œé€—å·åˆ†éš”")
):
    """
    æ–°é—»åˆ†ç±»æŸ¥çœ‹å™¨ä¸»é¡µé¢
    
    Args:
        filter: ä¸´æ—¶è¦†ç›–è¿‡æ»¤æ¨¡å¼
        platforms: æŒ‡å®šè¦æŸ¥çœ‹çš„å¹³å°ï¼ˆé€—å·åˆ†éš”ï¼‰
    """
    viewer_service, _ = get_services()
    
    # è§£æå¹³å°åˆ—è¡¨
    platform_list = None
    if platforms:
        platform_list = [p.strip() for p in platforms.split(",") if p.strip()]
    
    # è·å–åˆ†ç±»æ–°é—»æ•°æ®
    try:
        data = viewer_service.get_categorized_news(
            platforms=platform_list,
            limit=500,
            apply_filter=True,
            filter_mode=filter
        )
        
        return templates.TemplateResponse(
            "viewer.html",
            {
                "request": request,
                "data": data,
                "available_filters": ["strict", "moderate", "off"],
                "current_filter": filter or data.get("filter_mode", "moderate")
            }
        )
    except Exception as e:
        return HTMLResponse(
            content=f"""
            <html>
                <head><title>é”™è¯¯</title></head>
                <body>
                    <h1>åŠ è½½å¤±è´¥</h1>
                    <p>é”™è¯¯ä¿¡æ¯: {str(e)}</p>
                    <p>è¯·ç¡®ä¿å·²ç»è¿è¡Œè¿‡çˆ¬è™«å¹¶æœ‰æ–°é—»æ•°æ®ã€‚</p>
                </body>
            </html>
            """,
            status_code=500
        )


@app.get("/api/news")
async def api_news(
    platforms: Optional[str] = Query(None),
    limit: int = Query(500, ge=1, le=1000),
    filter_mode: Optional[str] = Query(None)
):
    """API: è·å–åˆ†ç±»æ–°é—»æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰"""
    viewer_service, _ = get_services()
    
    platform_list = None
    if platforms:
        platform_list = [p.strip() for p in platforms.split(",") if p.strip()]
    
    data = viewer_service.get_categorized_news(
        platforms=platform_list,
        limit=limit,
        apply_filter=True,
        filter_mode=filter_mode
    )
    
    return UnicodeJSONResponse(content=data)


@app.get("/api/categories")
async def api_categories():
    """API: è·å–åˆ†ç±»åˆ—è¡¨"""
    viewer_service, _ = get_services()
    categories = viewer_service.get_category_list()
    return UnicodeJSONResponse(content=categories)


@app.get("/api/filter/stats")
async def api_filter_stats():
    """API: è·å–è¿‡æ»¤ç»Ÿè®¡"""
    viewer_service, _ = get_services()
    stats = viewer_service.get_filter_stats()
    return UnicodeJSONResponse(content=stats)


@app.post("/api/filter/mode")
async def api_set_filter_mode(mode: str):
    """API: è®¾ç½®è¿‡æ»¤æ¨¡å¼"""
    viewer_service, _ = get_services()
    success = viewer_service.set_filter_mode(mode)
    return UnicodeJSONResponse(content={"success": success, "mode": mode})


@app.get("/api/blacklist/keywords")
async def api_blacklist_keywords():
    """API: è·å–é»‘åå•å…³é”®è¯"""
    viewer_service, _ = get_services()
    keywords = viewer_service.get_blacklist_keywords()
    return UnicodeJSONResponse(content={"keywords": keywords})


@app.post("/api/blacklist/reload")
async def api_reload_blacklist():
    """API: é‡æ–°åŠ è½½é»‘åå•"""
    viewer_service, _ = get_services()
    count = viewer_service.reload_blacklist()
    return UnicodeJSONResponse(content={"success": True, "keywords_count": count})


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "service": "TrendRadar News Viewer"}


# === å®šæ—¶ä»»åŠ¡ç›¸å…³ API ===

@app.post("/api/scheduler/start")
async def api_start_scheduler(interval: int = Query(30, ge=5, le=1440)):
    """
    å¯åŠ¨å®šæ—¶æ•°æ®è·å–ä»»åŠ¡
    
    Args:
        interval: è·å–é—´éš”ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤30ï¼ŒèŒƒå›´5-1440
    """
    start_scheduler(interval)
    return UnicodeJSONResponse(content={
        "success": True,
        "message": f"å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨ï¼Œé—´éš” {interval} åˆ†é’Ÿ",
        "interval_minutes": interval
    })


@app.post("/api/scheduler/stop")
async def api_stop_scheduler():
    """åœæ­¢å®šæ—¶æ•°æ®è·å–ä»»åŠ¡"""
    stop_scheduler()
    return UnicodeJSONResponse(content={
        "success": True,
        "message": "å®šæ—¶ä»»åŠ¡å·²åœæ­¢"
    })


@app.get("/api/scheduler/status")
async def api_scheduler_status():
    """è·å–å®šæ—¶ä»»åŠ¡çŠ¶æ€"""
    return UnicodeJSONResponse(content={
        "running": _scheduler_running,
        "interval_minutes": _fetch_interval_minutes,
        "last_fetch_time": _last_fetch_time.isoformat() if _last_fetch_time else None
    })


@app.post("/api/fetch")
async def api_fetch_now():
    """ç«‹å³æ‰§è¡Œä¸€æ¬¡æ•°æ®è·å–"""
    result = await fetch_news_data()
    return UnicodeJSONResponse(content=result)


@app.on_event("startup")
async def on_startup():
    """æœåŠ¡å™¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    # è¯»å–é…ç½®å†³å®šæ˜¯å¦è‡ªåŠ¨å¯åŠ¨å®šæ—¶ä»»åŠ¡
    try:
        config = load_config(str(project_root / "config" / "config.yaml"))
        viewer_config = config.get("viewer", {})
        
        auto_fetch = viewer_config.get("auto_fetch", False)
        fetch_interval = viewer_config.get("fetch_interval_minutes", 30)
        
        if auto_fetch:
            print(f"ğŸ“… è‡ªåŠ¨å¯åŠ¨å®šæ—¶è·å–ä»»åŠ¡ (é—´éš”: {fetch_interval} åˆ†é’Ÿ)")
            start_scheduler(fetch_interval)
            
            # å¯åŠ¨æ—¶ç«‹å³è·å–ä¸€æ¬¡
            if viewer_config.get("fetch_on_startup", True):
                asyncio.create_task(fetch_news_data())
    except Exception as e:
        print(f"âš ï¸ è¯»å–é…ç½®å¤±è´¥ï¼Œè·³è¿‡è‡ªåŠ¨å®šæ—¶ä»»åŠ¡: {e}")


def run_server(host: str = "0.0.0.0", port: int = 8080, auto_fetch: bool = False, interval: int = 30):
    """è¿è¡Œ Web æœåŠ¡å™¨"""
    import uvicorn
    
    print("=" * 60)
    print("ğŸš€ TrendRadar News Viewer Server")
    print("=" * 60)
    print(f"ğŸ“¡ Server Address: http://{host}:{port}")
    print(f"ğŸŒ Viewer URL: http://localhost:{port}/viewer")
    print(f"ğŸ“Š API Docs: http://localhost:{port}/docs")
    print("-" * 60)
    print("ğŸ“Œ å®šæ—¶ä»»åŠ¡ API:")
    print(f"   POST /api/scheduler/start?interval=30  å¯åŠ¨å®šæ—¶è·å–")
    print(f"   POST /api/scheduler/stop               åœæ­¢å®šæ—¶è·å–")
    print(f"   GET  /api/scheduler/status             æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€")
    print(f"   POST /api/fetch                        ç«‹å³è·å–ä¸€æ¬¡")
    print("=" * 60)
    print()
    
    uvicorn.run(app, host=host, port=port)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="TrendRadar News Viewer Server")
    parser.add_argument("--host", default="0.0.0.0", help="ç›‘å¬åœ°å€")
    parser.add_argument("--port", type=int, default=8080, help="ç›‘å¬ç«¯å£")
    
    args = parser.parse_args()
    run_server(host=args.host, port=args.port)
